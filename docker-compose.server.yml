services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: axon-backend
    restart: unless-stopped
    environment:
      - DATABASE_URL=sqlite+aiosqlite:///./data/axon.db
      - SECRET_KEY=${SECRET_KEY}
      - LLM_PROVIDER=ollama
      - OLLAMA_BASE_URL=http://axon-ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-mistral:7b-instruct}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - DEBUG=false
      - OUTPUTS_DIR=/app/outputs
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN:-}
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN:-}
    volumes:
      - axon-data:/app/data
      - axon-outputs:/app/outputs
    networks:
      - axon-net
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; r = httpx.get('http://localhost:8000/health'); assert r.status_code == 200"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.server
    container_name: axon-frontend
    restart: unless-stopped
    networks:
      - axon-net
      - proxy-net

  ollama:
    image: ollama/ollama:latest
    container_name: axon-ollama
    restart: unless-stopped
    volumes:
      - axon-ollama-data:/root/.ollama
    networks:
      - axon-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  axon-data:
  axon-outputs:
  axon-ollama-data:

networks:
  axon-net:
    driver: bridge
  proxy-net:
    external: true
